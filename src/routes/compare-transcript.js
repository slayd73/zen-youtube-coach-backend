// ======================================================// ⚖️ /compare-transcript — Versione Ultra PRO// Confronto testuale diretto tra 2 transcript// ======================================================import express from "express";import { callAIModel } from "../services/aiEngine.js";const router = express.Router();/** * Body richiesto: * * { *   "audience": "over60", *   "A": { *      "title": "Mio Video", *      "transcript": "testo..." *   }, *   "B": { *      "title": "Competitor", *      "transcript": "testo..." *   } * } */router.post("/", async (req, res) => {  try {    const { audience = "over60", A, B } = req.body || {};    if (!A?.transcript || !B?.transcript) {      return res.status(400).json({        success: false,        message:          "Servono due transcript validi: { A: {title, transcript}, B: {title, transcript} }"      });    }    const prompt = `Sei Zen YouTube Coach Pro.Confronta questi DUE transcript per pubblico ${audience}.Transcript A:Titolo: ${A.title || "A"}---${A.transcript}Transcript B:Titolo: ${B.title || "B"}---${B.transcript}Confronto richiesto:1) Punteggi da 0 a 10:   - hook   - chiarezza   - ritmo   - valore percepito   - adattamento Over 50/60/70   - coinvolgimento emotivo2) Quale dei due è migliore e perché (short reason)3) Miglioramenti per A e B4) "What A Should Steal from B" e viceversa5) "Pattern condivisi"Rispondi SOLO con JSON:{  "scores": {    "A": { "hook": 0, "clarity": 0, "rhythm": 0, "value": 0, "nicheFit": 0, "emotion": 0 },    "B": { "hook": 0, "clarity": 0, "rhythm": 0, "value": 0, "nicheFit": 0, "emotion": 0 }  },  "winner": "A" or "B",  "reason": "...",  "improvements": {    "A": ["...", "..."],    "B": ["...", "..."]  },  "stealFromEachOther": {    "A_should_steal_from_B": ["...", "..."],    "B_should_steal_from_A": ["...", "..."]  },  "patternsShared": ["...", "..."]}`.trim();    // Prima chiamata → Groq    let raw = await callAIModel(prompt, "text", {      provider: "groq",      temperature: 0.2,      maxTokens: 5000    });    const extractJSON = (txt) => {      try {        const first = txt.indexOf("{");        const last = txt.lastIndexOf("}");        if (first === -1 || last === -1) return null;        return JSON.parse(txt.substring(first, last + 1));      } catch {        return null;      }    };    let parsed = extractJSON(raw);    if (!parsed) {      // fallback GPT-4o-mini      raw = await callAIModel(prompt, "text", {        provider: "openai",        model: "gpt-4o-mini",        temperature: 0.05,        maxTokens: 6500      });      parsed = extractJSON(raw);    }    if (!parsed) {      return res.status(500).json({        success: false,        message: "AI ha prodotto JSON non valido.",        raw      });    }    return res.json({      success: true,      audience,      data: parsed    });  } catch (err) {    console.error("❌ /compare-transcript error:", err);    return res.status(500).json({      success: false,      message: "Errore interno: " + err.message    });  }});export default router;